```python
import os
import re
import json
import shutil
from multiprocessing import Pool, Manager, cpu_count
from docx import Document
from docx.shared import RGBColor
import xlsxwriter
from tqdm import tqdm

# === CONFIG ===
INPUT_FILE     = "input.txt"
CHUNK_SIZE     = 2000
MOBILE_REGEX   = r"(?<!\d)(?:\+91[\-\s]?|91[\-\s]?|91|0)?[6-9]\d{9}(?!\d)"
OUTPUT_DOCX    = "final_output_mobile.docx"
OUTPUT_XLSX    = "final_output_mobile.xlsx"
TEMP_DIR       = "temp_parts"

# === RECURSIVE FIELD FINDER WITH JSON-STRING PARSING ===
def find_field(obj, val):
    """
    Recursively search obj (dict, list, or JSON string) for a leaf matching val.
    Returns list of keys leading to val, or None.
    """
    if isinstance(obj, dict):
        for k, v in obj.items():
            # If value is a dict or list, recurse
            if isinstance(v, (dict, list)):
                sub = find_field(v, val)
                if sub:
                    return [k] + sub
            # If value is a string, attempt to parse JSON inside
            elif isinstance(v, str):
                # direct match
                if str(v) == val:
                    return [k]
                # comma-separated primitive match
                parts = [p.strip() for p in v.split(',')]
                if val in parts:
                    return [k]
                # try JSON parse
                try:
                    inner = json.loads(v)
                except (ValueError, TypeError):
                    pass
                else:
                    sub = find_field(inner, val)
                    if sub:
                        return [k] + sub
            else:
                if str(v) == val:
                    return [k]
    elif isinstance(obj, list):
        for idx, item in enumerate(obj):
            sub = find_field(item, val)
            if sub:
                return [f"[{idx}]"] + sub
    return None

# === PARSE RECORDS ===
def load_records():
    records = []
    last_id = None
    ct_re   = re.compile(r"^CreateTime:(\d+)\s+(.*)$")
    with open(INPUT_FILE, 'r', encoding='utf-8', errors='ignore') as f:
        for raw in f:
            line = raw.rstrip('\r\n')
            m = ct_re.match(line)
            if m and last_id is not None:
                records.append((last_id, m.group(1), m.group(2)))
            elif line.strip():
                last_id = line.strip()
    return records

# === CHUNKING ===
def chunk_records(records):
    for i in range(0, len(records), CHUNK_SIZE):
        yield records[i:i+CHUNK_SIZE], i // CHUNK_SIZE

# === PROCESS ONE CHUNK ===
def process_chunk(args):
    chunk, idx, result_list = args
    pattern = re.compile(MOBILE_REGEX)

    doc = Document()
    matches_data = []

    for identifier, ts, payload in chunk:
        matches = list(pattern.finditer(payload))
        if not matches:
            continue

        # attempt JSON parse
        try:
            obj = json.loads(payload)
        except json.JSONDecodeError:
            obj = {}

        # build Word paragraph
        para = doc.add_paragraph(f"{identifier} | CreateTime:{ts} | ")
        last = 0
        for mt in matches:
            s, e = mt.span()
            if s > last:
                para.add_run(payload[last:s])
            mobile = mt.group()
            run = para.add_run(mobile)
            run.font.color.rgb = RGBColor(255, 0, 0)
            last = e

            # find field name, including nested JSON-string
            path = find_field(obj, mobile) or []
            field = ".".join(path)

            matches_data.append((identifier, ts, payload, mobile, field))

        if last < len(payload):
            para.add_run(payload[last:])

        # append field names in red
        fields = [fld for *_, fld in matches_data[-len(matches):]]
        para.add_run(" | field: ")
        for i, fld in enumerate(fields):
            if i:
                para.add_run(", ")
            fr = para.add_run(fld)
            fr.font.color.rgb = RGBColor(255, 0, 0)

    # save Word chunk
    if matches_data:
        os.makedirs(TEMP_DIR, exist_ok=True)
        doc.save(os.path.join(TEMP_DIR, f"chunk_{idx}.docx"))

    result_list.append((matches_data, len(chunk), len(matches_data)))

# === MERGE WORD ===
def merge_word():
    merged = Document()
    for fn in tqdm(sorted(os.listdir(TEMP_DIR)), desc="Merging Word"): 
        if not fn.endswith(".docx"): continue
        doc = Document(os.path.join(TEMP_DIR, fn))
        for para in doc.paragraphs:
            new_p = merged.add_paragraph()
            for run in para.runs:
                nr = new_p.add_run(run.text)
                if run.font.color and run.font.color.rgb:
                    nr.font.color.rgb = run.font.color.rgb
                nr.bold = run.bold; nr.italic = run.italic; nr.underline = run.underline
    merged.save(OUTPUT_DOCX)

# === WRITE EXCEL ===
def write_excel(all_matches):
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws = wb.add_worksheet()
    red = wb.add_format({'font_color':'red'})

    ws.write_row(0, 0, ["Identifier","Timestamp","Payload","Mobile","Field"])
    r = 1
    for idf, ts, payload, mobile, field in all_matches:
        ws.write(r, 0, idf)
        ws.write(r, 1, ts)
        ws.write(r, 2, payload)
        ws.write(r, 3, mobile, red)
        ws.write(r, 4, field)
        r += 1
    wb.close()

# === MAIN ===
if __name__ == "__main__":
    if os.path.isdir(TEMP_DIR):
        shutil.rmtree(TEMP_DIR)

    print("=== MOBILE EXTRACTOR w/ FIELD NAMES (Enhanced) ===")
    print(f"Using regex: {MOBILE_REGEX}")

    records = load_records()
    print(f"Found {len(records)} records.")
    chunks = list(chunk_records(records))

    mgr = Manager()
    results = mgr.list()

    with Pool(min(cpu_count(), len(chunks))) as pool:
        list(tqdm(pool.imap_unordered(
            process_chunk,
            [(chunk, idx, results) for chunk, idx in chunks]
        ), total=len(chunks), desc="Processing"))

    # aggregate
    all_matches = []
    for data, _, _ in results:
        all_matches.extend(data)

    if os.path.isdir(TEMP_DIR):
        merge_word()
    write_excel(all_matches)

    shutil.rmtree(TEMP_DIR)
    print(f"\n→ Word: {OUTPUT_DOCX}\n→ Excel: {OUTPUT_XLSX}")
```
