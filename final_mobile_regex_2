import os
import re
import shutil
from multiprocessing import Pool, Manager, cpu_count
from docx import Document
from docx.shared import RGBColor
import xlsxwriter
from tqdm import tqdm

# === CONFIG ===
INPUT_FILE     = "input.txt"
CHUNK_SIZE     = 2000
MOBILE_REGEX   = r"(?<!\d)(?:\+91[\-\s]?|91[\-\s]?|91|0)?[6-9]\d{9}(?!\d)"
OUTPUT_DOCX    = "final_output_mobile_special.docx"
OUTPUT_XLSX    = "final_output_mobile_special.xlsx"
TEMP_DIR       = "temp_parts"

# === LOAD RECORDS ===
def load_records():
    records = []
    last_id = None
    ct_re = re.compile(r"^CreateTime:(\d+)\s+(.*)$")
    with open(INPUT_FILE, 'r', encoding='utf-8', errors='ignore') as f:
        for raw in f:
            line = raw.rstrip('\r\n')
            m = ct_re.match(line)
            if m and last_id:
                records.append((last_id, m.group(1), m.group(2)))
            elif line.strip():
                last_id = line.strip()
    return records

# === CHUNK RECORDS ===
def chunk_records(records):
    for i in range(0, len(records), CHUNK_SIZE):
        yield records[i:i+CHUNK_SIZE], i//CHUNK_SIZE

# === FIELD-FINDER FOR ESCAPED JSON STRINGS ===
def find_field_in_unescaped(payload, mobile):
    # turn \" into " so we can regex-search nested JSON
    unesc = payload.replace('\\"', '"')
    m = re.search(r'"([^"]+)"\s*:\s*' + re.escape(mobile), unesc)
    return m.group(1) if m else ""

# === PROCESS ONE CHUNK ===
def process_chunk(args):
    chunk, idx, result_list = args
    pat = re.compile(MOBILE_REGEX)
    doc = Document()
    matches_data = []
    seen = matched = 0

    for identifier, ts, payload in chunk:
        seen += 1
        for mt in pat.finditer(payload):
            matched += 1
            s, e = mt.span()
            mobile = mt.group()

            # find the key name by unescaping
            field = find_field_in_unescaped(payload, mobile)

            # record for Excel
            matches_data.append((identifier, ts, payload, mobile, field))

        # if any mobiles in this payload, build a single paragraph
        if matched > 0:
            # but we want per-record paragraph; filter this record's mobiles
            rec_mobiles = [m.group() for m in pat.finditer(payload)]
            para = doc.add_paragraph(f"{identifier} | CreateTime:{ts} | ")
            last = 0
            for mv in rec_mobiles:
                m0 = pat.search(payload, last)
                if not m0: break
                s0, e0 = m0.span()
                if s0 > last:
                    para.add_run(payload[last:s0])
                run = para.add_run(mv)
                run.font.color.rgb = RGBColor(255,0,0)
                last = e0
            if last < len(payload):
                para.add_run(payload[last:])
            # append fields
            fields = [find_field_in_unescaped(payload, mv) for mv in rec_mobiles]
            para.add_run(" | field: ")
            for i,fld in enumerate(fields):
                if i: para.add_run(", ")
                fr = para.add_run(fld)
                fr.font.color.rgb = RGBColor(255,0,0)

    # save chunk docx if any matches
    if matches_data:
        os.makedirs(TEMP_DIR, exist_ok=True)
        doc.save(os.path.join(TEMP_DIR, f"chunk_{idx}.docx"))

    result_list.append((matches_data, seen, matched))

# === MERGE WORD CHUNKS ===
def merge_word():
    merged = Document()
    for fn in tqdm(sorted(os.listdir(TEMP_DIR)), desc="Merging Word"):
        if not fn.endswith(".docx"):
            continue
        doc = Document(os.path.join(TEMP_DIR, fn))
        for para in doc.paragraphs:
            p2 = merged.add_paragraph()
            for run in para.runs:
                nr = p2.add_run(run.text)
                if run.font.color and run.font.color.rgb:
                    nr.font.color.rgb = run.font.color.rgb
                nr.bold = run.bold; nr.italic = run.italic; nr.underline = run.underline
    merged.save(OUTPUT_DOCX)

# === WRITE EXCEL ===
def write_excel(all_matches):
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws = wb.add_worksheet()
    red = wb.add_format({'font_color':'red'})
    ws.write_row(0, 0, ["Identifier","Timestamp","Payload","Mobile","Field"])
    row = 1
    for identifier, ts, payload, mobile, field in all_matches:
        ws.write(row, 0, identifier)
        ws.write(row, 1, ts)
        ws.write(row, 2, payload)
        ws.write(row, 3, mobile, red)
        ws.write(row, 4, field)
        row += 1
    wb.close()

# === MAIN ===
if __name__ == "__main__":
    if os.path.isdir(TEMP_DIR):
        shutil.rmtree(TEMP_DIR)

    print("=== MOBILE EXTRACTOR (special) ===")
    recs = load_records()
    print(f"Total records found: {len(recs)}")
    chunks = list(chunk_records(recs))

    mgr = Manager()
    results = mgr.list()
    with Pool(min(cpu_count(), len(chunks))) as pool:
        list(tqdm(pool.imap_unordered(
            process_chunk,
            [(chunk, idx, results) for chunk, idx in chunks]
        ), total=len(chunks), desc="Processing chunks"))

    all_matches = []
    tot = has = 0
    for data, seen, matched in results:
        all_matches.extend(data)
        tot += seen
        has += matched

    print(f"Records scanned: {tot}, with mobile matches: {has}, total matches: {len(all_matches)}")

    if os.path.isdir(TEMP_DIR):
        merge_word()
    write_excel(all_matches)

    shutil.rmtree(TEMP_DIR)
    print(f"\n→ Word saved to {OUTPUT_DOCX}")
    print(f"→ Excel saved to {OUTPUT_XLSX}")
