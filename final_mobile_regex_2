import os
import re
import json
import shutil
from multiprocessing import Pool, Manager, cpu_count
from docx import Document
from docx.shared import RGBColor
import xlsxwriter
from tqdm import tqdm

# === CONFIG ===
INPUT_FILE   = "input.txt"
CHUNK_SIZE   = 2000
MOBILE_REGEX = r"(?<!\d)(?:\+91[\-\s]?|91[\-\s]?|91|0)?[6-9]\d{9}(?!\d)"
OUTPUT_DOCX  = "final_output_mobile_nested.docx"
OUTPUT_XLSX  = "final_output_mobile_nested.xlsx"
TEMP_DIR     = "temp_parts"

def clean_text(s: str) -> str:
    return s.replace('\x00', '')

def flatten_json(obj, prefix=""):
    flat = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            path = f"{prefix}{k}"
            if isinstance(v, dict) or isinstance(v, list):
                flat.update(flatten_json(v, path + "."))
            elif isinstance(v, str) and v.strip().startswith(("{", "[")):
                # parse inner JSON string
                try:
                    inner = json.loads(v)
                except Exception:
                    flat[path] = v
                else:
                    flat.update(flatten_json(inner, path + "."))
            else:
                flat[path] = v
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            flat.update(flatten_json(item, f"{prefix}[{i}]."))
    return flat

def load_records():
    records = []
    last_id = None
    ct_re = re.compile(r"^CreateTime:(\d+)\s+(.*)$")
    with open(INPUT_FILE, 'r', encoding='utf-8', errors='ignore') as f:
        for raw in f:
            line = raw.rstrip('\r\n')
            m = ct_re.match(line)
            if m and last_id:
                ts = m.group(1)
                payload = clean_text(m.group(2))
                records.append((clean_text(last_id), ts, payload))
            elif line.strip():
                last_id = line.strip()
    return records

def chunk_records(records):
    for i in range(0, len(records), CHUNK_SIZE):
        yield records[i:i+CHUNK_SIZE], i//CHUNK_SIZE

def extract_after_flat(payload):
    # find "after":{ ... } block
    m = re.search(r'"after"\s*:\s*\{', payload)
    if not m:
        return {}
    start = m.end() - 1
    depth = 0
    for i in range(start, len(payload)):
        if payload[i] == '{':
            depth += 1
        elif payload[i] == '}':
            depth -= 1
        if depth == 0:
            block = payload[start:i+1]
            try:
                after_obj = json.loads(block)
                return flatten_json(after_obj, prefix="after.")
            except json.JSONDecodeError:
                return {}
    return {}

def process_chunk(args):
    chunk, idx, result_list = args
    pat = re.compile(MOBILE_REGEX)
    doc = Document()
    matches = []
    recs_seen = recs_with_mobile = 0

    for ident, ts, payload in chunk:
        recs_seen += 1
        for m in pat.finditer(payload):
            recs_with_mobile += 1
            num = m.group()

            # try full JSON
            flat = {}
            try:
                obj = json.loads(payload)
                flat = flatten_json(obj)
            except json.JSONDecodeError:
                # fallback to after block
                flat = extract_after_flat(payload)

            # find field name
            field = ""
            for path, val in flat.items():
                if str(val) == num:
                    field = path
                    break

            matches.append((ident, ts, payload, num, field))

        if matches and matches[-1][0] == ident:
            # build Word paragraph once per record
            para = doc.add_paragraph(f"{ident} | CreateTime:{ts} | ")
            last = 0
            rec_nums = [num for (i2,_,_,num,_) in matches if i2 == ident]
            for num in rec_nums:
                m2 = pat.search(payload, last)
                s, e = m2.span()
                if s > last:
                    para.add_run(payload[last:s])
                run = para.add_run(num)
                run.font.color.rgb = RGBColor(255,0,0)
                last = e
            if last < len(payload):
                para.add_run(payload[last:])
            # append fields
            fields = [fld for (i2,_,_,num,fld) in matches if i2 == ident]
            para.add_run(" | field: ")
            for idxf, fld in enumerate(fields):
                if idxf: para.add_run(", ")
                fr = para.add_run(fld)
                fr.font.color.rgb = RGBColor(255,0,0)

    if matches:
        os.makedirs(TEMP_DIR, exist_ok=True)
        doc.save(os.path.join(TEMP_DIR, f"chunk_{idx}.docx"))

    result_list.append((matches, recs_seen, recs_with_mobile))

def merge_word():
    merged = Document()
    for fn in sorted(os.listdir(TEMP_DIR)):
        if not fn.endswith(".docx"): continue
        sub = Document(os.path.join(TEMP_DIR, fn))
        for para in sub.paragraphs:
            p2 = merged.add_paragraph()
            for run in para.runs:
                nr = p2.add_run(run.text)
                if run.font.color and run.font.color.rgb:
                    nr.font.color.rgb = run.font.color.rgb
                nr.bold = run.bold; nr.italic = run.italic; nr.underline = run.underline
    merged.save(OUTPUT_DOCX)

def write_excel(all_matches):
    wb = xlsxwriter.Workbook(OUTPUT_XLSX)
    ws = wb.add_worksheet()
    red = wb.add_format({'font_color':'red'})
    ws.write_row(0,0,["Identifier","Timestamp","Payload","Mobile","Field"])
    row = 1
    for ident, ts, payload, num, field in all_matches:
        ws.write(row,0,ident)
        ws.write(row,1,ts)
        ws.write(row,2,payload)
        ws.write(row,3,num, red)
        ws.write(row,4,field)
        row += 1
    wb.close()

if __name__=="__main__":
    if os.path.isdir(TEMP_DIR):
        shutil.rmtree(TEMP_DIR)

    print("=== MOBILE EXTRACTOR (Nested Payload Special) ===")
    records = load_records()
    print(f"Total records found: {len(records)}")
    chunks = list(chunk_records(records))

    mgr = Manager()
    results = mgr.list()
    with Pool(min(cpu_count(), len(chunks))) as pool:
        list(tqdm(pool.imap_unordered(
            process_chunk,
            [(chunk, idx, results) for chunk, idx in chunks]
        ), total=len(chunks), desc="Processing chunks"))

    all_matches = []
    tot = has = 0
    for data, recs, with_mobile in results:
        all_matches.extend(data)
        tot += recs
        has += with_mobile

    print(f"Records scanned: {tot}, with mobile: {has}, matches: {len(all_matches)}")

    if os.path.isdir(TEMP_DIR):
        merge_word()
    write_excel(all_matches)
    shutil.rmtree(TEMP_DIR)
    print(f"\n→ Word: {OUTPUT_DOCX}\n→ Excel: {OUTPUT_XLSX}")
